{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import struct\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pydot\n",
    "import pydotplus\n",
    "import graphviz\n",
    "import scipy\n",
    "import scipy.stats as sts\n",
    "import numpy.random as npr\n",
    "from logging.config import dictConfig\n",
    "from scipy.stats import norm\n",
    "from sklearn import metrics\n",
    "from keras import regularizers\n",
    "from keras.layers import Dense, Activation, Input, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras_tqdm import TQDMNotebookCallback as ktqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, confusion_matrix\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_graph(history, index, label, name):\n",
    "    \"\"\"Plot the graph for the given history metrics.\"\"\"\n",
    "    plt.plot(history.history[index], label='Training %s = %0.6f' % (label, history.history[index][-1]))\n",
    "    plt.plot(history.history['val_%s'%index] , label='Testing %s = %0.6f' % (label, history.history['val_%s'%index][-1]))\n",
    "    plt.title('Model %s'%label, fontsize=15)\n",
    "    plt.ylabel(label)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.savefig(name, bbox_inches=None)\n",
    "    #plt.figure(figsize=(80,40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "beta005 = 0.05\n",
    "beta02 = 0.2\n",
    "beta05 = 0.5\n",
    "beta1 = 1\n",
    "beta3 = 3\n",
    "beta10 = 10\n",
    "\n",
    "def custom_activation(x):\n",
    "    return (K.sigmoid(x * 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging Discrete Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 50\n",
    "size = 10000\n",
    "n = step * size\n",
    "train_size = 0.70\n",
    "test_size = 1 - train_size\n",
    "width = np.ceil(np.log2(n)).astype(int)\n",
    "predecessors = np.arange(0, n, step)\n",
    "predecessors = np.array([\n",
    "    (predecessors[i]) for i in range(size)\n",
    "]).astype(int)\n",
    "predecessors, predecessors.shape, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_predecessors = np.array([(((i / size))) for i in range(size)])\n",
    "\n",
    "cumulative_predecessors, cumulative_predecessors.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predecessors_bits = np.array([\n",
    "    list(np.binary_repr(i, width)) for i in np.arange(0, n, step)\n",
    "]).astype(int)\n",
    "np.set_printoptions(threshold=100)\n",
    "predecessors_bits, predecessors_bits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create training + testing set\n",
    "## L'idea è utilizzare una permutazione casuale per ottenere gli elementi presenti da 0 a size\n",
    "rnd_ind = npr.permutation(size)\n",
    "rnd_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutated_preds, permutated_cums = predecessors[np.ndarray.tolist(rnd_ind)], cumulative_predecessors[np.ndarray.tolist(rnd_ind)]\n",
    "train_ind, train_lab = permutated_preds[:int(size * 0.70)], permutated_cums[:int(size * 0.70)]\n",
    "test_ind, test_lab = permutated_preds[int(size * 0.70):], permutated_cums[int(size * 0.70):]\n",
    "permutated_preds, permutated_cums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind_2 = np.array([list(np.binary_repr(train_ind[i], width)) for i in range(train_ind.size)]).astype(int)\n",
    "train_ind_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ind_2 = np.array([list(np.binary_repr(test_ind[i], width)) for i in range(test_ind.size)]).astype(int)\n",
    "test_ind_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics, optimizers\n",
    "\n",
    "def build_model(neurons):\n",
    "    \"\"\" Return keras network model \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(neurons), input_dim=neurons, name=\"Input_dense_layer\", activation=\"sigmoid\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, name=\"Output_dense_layer\", activation=\"sigmoid\"))\n",
    "    model.compile(\n",
    "        loss='mean_squared_error', \n",
    "        optimizer=\"sgd\",\n",
    "        metrics=['mean_absolute_error'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "model_20 = build_model(width)\n",
    "model_50 = build_model(width)\n",
    "model_75 = build_model(width)\n",
    "model_100 = build_model(width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_20 = model_20.fit(\n",
    "    train_ind_2, \n",
    "    train_lab,\n",
    "    epochs=20,\n",
    "    shuffle=True,\n",
    "    batch_size=256,\n",
    "    verbose=0,\n",
    "    callbacks=[ktqdm(metric_format=\"{name}: {value:e}\")],\n",
    "    validation_data=(test_ind_2, test_lab)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_50 = model_50.fit(\n",
    "    train_ind_2, \n",
    "    train_lab,\n",
    "    epochs=50,\n",
    "    shuffle=True,\n",
    "    batch_size=256,\n",
    "    verbose=0,\n",
    "    callbacks=[ktqdm(metric_format=\"{name}: {value:e}\")],\n",
    "    validation_data=(test_ind_2, test_lab)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_75 = model_75.fit(\n",
    "    train_ind_2, \n",
    "    train_lab,\n",
    "    epochs=_75,\n",
    "    shuffle=True,\n",
    "    batch_size=256,\n",
    "    verbose=0,\n",
    "    callbacks=[ktqdm(metric_format=\"{name}: {value:e}\")],\n",
    "    validation_data=(test_ind_2, test_lab)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_100 = model_100.fit(\n",
    "    train_ind_2, \n",
    "    train_lab,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    batch_size=256,\n",
    "    verbose=0,\n",
    "    callbacks=[ktqdm(metric_format=\"{name}: {value:e}\")],\n",
    "    validation_data=(test_ind_2, test_lab)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plot_history_graph(history_20, 'mean_absolute_error', 'mae', \"1_mae_uniform.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_graph(history_20, 'loss', 'loss', \"1_mse_uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_graph(history_50, 'mean_absolute_error', 'mae', \"2_mae_uniform.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_graph(history_50, 'loss', 'loss', \"2_mse_uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_graph(history_75, 'mean_absolute_error', 'mae', \"3_mae_uniform.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_graph(history_75, 'loss', 'loss', \"3_mse_uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_graph(history_100, 'mean_absolute_error', 'mae', \"4_mae_uniform.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_graph(history_100, 'loss', 'loss', \"4_mse_uniform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(num, width, model, size):\n",
    "    bin = np.array([list(np.binary_repr(num, width))])\n",
    "    #print(\"Prediction on \", num, \":\\t \", model.predict(bin))\n",
    "    return int(np.reshape(np.ceil(model.predict(bin) * size), 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_errors(model, size, width, predecessors):\n",
    "    errors = []\n",
    "    ## L'operazione è ripetuta size volte\n",
    "    for x in range(size):\n",
    "        ## L'indice che mi aspetto è in posizione x di rnd_ind\n",
    "        expected_index = rnd_ind[x]\n",
    "        print(x)\n",
    "        ## Ripeto la predizione step volte\n",
    "        for i in range(step):\n",
    "            ## Predico predecessors[expected_index] + i\n",
    "            predicted_index = prediction(predecessors[expected_index] + i, width, model, size)\n",
    "            ## Calcolo la distanza tra l'indice ottenuto e l'indice atteso\n",
    "            errors.append(abs(expected_index - predicted_index))\n",
    "    ## Plot degli errori\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
